{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kaiyoo88/tutorial-youtube-comments-crawling?scriptVersionId=237163256\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import googleapiclient.discovery\nfrom googleapiclient.errors import HttpError\n\nimport pandas as pd\nimport time\nimport tqdm","metadata":{"execution":{"iopub.status.busy":"2025-05-01T06:10:49.45941Z","iopub.execute_input":"2025-05-01T06:10:49.45968Z","iopub.status.idle":"2025-05-01T06:10:51.183361Z","shell.execute_reply.started":"2025-05-01T06:10:49.45965Z","shell.execute_reply":"2025-05-01T06:10:51.182194Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# YouTube API key\nAPI_KEY = \"YOUR-API-KEY\" # YOUR-API-KEY\nyoutube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=API_KEY)","metadata":{"execution":{"iopub.status.busy":"2025-05-01T06:11:15.686307Z","iopub.execute_input":"2025-05-01T06:11:15.686713Z","iopub.status.idle":"2025-05-01T06:11:15.705548Z","shell.execute_reply.started":"2025-05-01T06:11:15.686677Z","shell.execute_reply":"2025-05-01T06:11:15.704481Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Get video ids for query. Youtube API allows only up to 50 videos\n\ndef get_video_ids(query, max_results=100):\n    video_ids = []\n    results_per_page = 50  # YouTube API maxResults \n    pages = (max_results + results_per_page - 1) // results_per_page  # calculate #pages\n    next_page_token = None\n    \n    for _ in range(pages): # call api as many times as #pages\n        try:\n            request = youtube.search().list(\n                q=query,\n                part=\"snippet\",\n                maxResults=results_per_page,\n                type=\"video\",\n                pageToken=next_page_token\n            )\n            response = request.execute()      \n\n            # Only check if 'id' key exists and 'videoId' is accessible\n            for item in response['items']:\n                if isinstance(item, dict) and 'id' in item and 'videoId' in item['id']:\n                    video_ids.append(item['id']['videoId'])\n\n            next_page_token = response.get('nextPageToken')\n            if not next_page_token:\n                break\n\n        except HttpError as e:\n            error_reason = e.resp.get('reason')\n            if error_reason == 'quotaExceeded':\n                print(\"Quota exceeded. Saving collected data...\")\n                save_data_to_csv(video_comments)\n                exit()\n            else:\n                print(f\"An error occurred: {e}\")\n                \n    return video_ids[:max_results]","metadata":{"execution":{"iopub.status.busy":"2025-05-01T06:13:01.269187Z","iopub.execute_input":"2025-05-01T06:13:01.269652Z","iopub.status.idle":"2025-05-01T06:13:01.279619Z","shell.execute_reply.started":"2025-05-01T06:13:01.269614Z","shell.execute_reply":"2025-05-01T06:13:01.27819Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Get comments for 1 video. Youtube API allows only up to 100 comments per video\ndef get_top_korean_comments(video_id, max_results=100):\n    comments = []\n    try:\n        request = youtube.commentThreads().list(\n            part=\"snippet\",\n            videoId=video_id,\n            maxResults=max_results,\n            textFormat=\"plainText\"\n        )\n        response = request.execute()\n\n        for item in response['items']:\n            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n            comments.append(comment)  \n                \n    except HttpError as e:\n        error_reason = e.resp.get('reason')\n        if error_reason == 'commentsDisabled':\n            print(f\"Comments are disabled for video {video_id}. Skipping.\")\n        elif error_reason == 'quotaExceeded':\n            print(\"Quota exceeded. Saving collected data...\")\n            save_data_to_csv(video_comments)\n            exit()\n        else:\n            print(f\"An error occurred: {e}\")\n    \n    return comments","metadata":{"execution":{"iopub.status.busy":"2025-05-01T06:15:04.832712Z","iopub.execute_input":"2025-05-01T06:15:04.833145Z","iopub.status.idle":"2025-05-01T06:15:04.840788Z","shell.execute_reply.started":"2025-05-01T06:15:04.833109Z","shell.execute_reply":"2025-05-01T06:15:04.839621Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Make data to dataframe\n# video_comments looks like: {\"4DUYBXdUYzA\": [\"와 재밌다\", \"재미없다\", ]}\ndef save_data_to_csv(video_comments):    \n    \n    data = {\"Video_ID\": [], \"Comment\": []}\n    \n    for video_id, comments in video_comments.items():\n        for comment in comments:\n            data[\"Video_ID\"].append(video_id)\n            data[\"Comment\"].append(comment)\n\n    df = pd.DataFrame(data)\n    \n    # Export to CSV \n    df.to_csv(\"youtube_comments.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2025-05-01T06:15:21.008001Z","iopub.execute_input":"2025-05-01T06:15:21.008779Z","iopub.status.idle":"2025-05-01T06:15:21.014534Z","shell.execute_reply.started":"2025-05-01T06:15:21.008735Z","shell.execute_reply":"2025-05-01T06:15:21.013431Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"participants = [\"흑백요리사\",\"백종원\",\"안성재\",\"에드워드 리\",\"나폴리 맛피아\",\"트리플스타\",\"요리하는 돌아이\",\"최현석\",\"장호준\",\"여경래\",\"안유성\",\"정지선\",\"최강록\",\"조은주\",\"오세득\",\"파브리치오 페라리\",\"이영숙\",\"선경 롱게스트\",\"김도윤\",\"박준우\"]","metadata":{"execution":{"iopub.status.busy":"2025-05-01T06:18:14.367668Z","iopub.execute_input":"2025-05-01T06:18:14.36807Z","iopub.status.idle":"2025-05-01T06:18:14.374234Z","shell.execute_reply.started":"2025-05-01T06:18:14.368034Z","shell.execute_reply":"2025-05-01T06:18:14.372984Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"video_comments = {}\n# Ex: {\"4DUYBXdUYzA\": [\"와 재밌다\", \"재미없다\", ]}\n\nstart = time.time()\nquery_baisic = \"흑백요리사\"\n\nfor participant in tqdm.tqdm(participants):\n    query = query_baisic + \" \" + participant \n\n    try:\n        video_ids = get_video_ids(query, max_results=50) \n\n        for video_id in video_ids:\n            comments = get_top_korean_comments(video_id)\n            video_comments[video_id] = comments\n    except HttpError as e:\n        if e.resp.get('reason') == 'quotaExceeded':\n            print(\"Quota exceeded. Saving collected data...\")\n            save_data_to_csv(video_comments)\n            exit()\n\n    end = time.time()    \n    print(f\"{end - start}s for query: {query}\")    \n\nsave_data_to_csv(video_comments)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T06:18:15.984861Z","iopub.execute_input":"2025-05-01T06:18:15.985287Z","iopub.status.idle":"2025-05-01T06:19:28.839882Z","shell.execute_reply.started":"2025-05-01T06:18:15.985245Z","shell.execute_reply":"2025-05-01T06:19:28.838614Z"}},"outputs":[{"name":"stderr","text":"  5%|▌         | 1/20 [00:05<01:42,  5.38s/it]","output_type":"stream"},{"name":"stdout","text":"5.391307592391968s for query: 흑백요리사 흑백요리사\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 2/20 [00:09<01:23,  4.62s/it]","output_type":"stream"},{"name":"stdout","text":"9.482851028442383s for query: 흑백요리사 백종원\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 3/20 [00:13<01:12,  4.28s/it]","output_type":"stream"},{"name":"stdout","text":"13.347225427627563s for query: 흑백요리사 안성재\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 4/20 [00:17<01:04,  4.04s/it]","output_type":"stream"},{"name":"stdout","text":"17.01892900466919s for query: 흑백요리사 에드워드 리\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 5/20 [00:21<01:00,  4.06s/it]","output_type":"stream"},{"name":"stdout","text":"21.124089241027832s for query: 흑백요리사 나폴리 맛피아\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 6/20 [00:24<00:54,  3.91s/it]","output_type":"stream"},{"name":"stdout","text":"24.747091054916382s for query: 흑백요리사 트리플스타\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 7/20 [00:28<00:48,  3.73s/it]","output_type":"stream"},{"name":"stdout","text":"28.09051251411438s for query: 흑백요리사 요리하는 돌아이\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 8/20 [00:31<00:44,  3.71s/it]","output_type":"stream"},{"name":"stdout","text":"31.75338339805603s for query: 흑백요리사 최현석\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 9/20 [00:35<00:39,  3.59s/it]","output_type":"stream"},{"name":"stdout","text":"35.079195499420166s for query: 흑백요리사 장호준\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 10/20 [00:38<00:34,  3.48s/it]","output_type":"stream"},{"name":"stdout","text":"38.33418536186218s for query: 흑백요리사 여경래\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▌    | 11/20 [00:41<00:31,  3.53s/it]","output_type":"stream"},{"name":"stdout","text":"41.95890736579895s for query: 흑백요리사 안유성\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 12/20 [00:46<00:30,  3.78s/it]","output_type":"stream"},{"name":"stdout","text":"46.31067395210266s for query: 흑백요리사 정지선\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 13/20 [00:50<00:26,  3.80s/it]","output_type":"stream"},{"name":"stdout","text":"50.16686463356018s for query: 흑백요리사 최강록\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 14/20 [00:53<00:22,  3.69s/it]","output_type":"stream"},{"name":"stdout","text":"53.61259913444519s for query: 흑백요리사 조은주\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 15/20 [00:56<00:17,  3.54s/it]","output_type":"stream"},{"name":"stdout","text":"56.788427114486694s for query: 흑백요리사 오세득\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 16/20 [00:59<00:12,  3.25s/it]","output_type":"stream"},{"name":"stdout","text":"59.36181950569153s for query: 흑백요리사 파브리치오 페라리\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 17/20 [01:02<00:09,  3.28s/it]","output_type":"stream"},{"name":"stdout","text":"62.72652268409729s for query: 흑백요리사 이영숙\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 18/20 [01:06<00:06,  3.41s/it]","output_type":"stream"},{"name":"stdout","text":"66.44850420951843s for query: 흑백요리사 선경 롱게스트\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 19/20 [01:09<00:03,  3.31s/it]","output_type":"stream"},{"name":"stdout","text":"69.50300288200378s for query: 흑백요리사 김도윤\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20/20 [01:12<00:00,  3.63s/it]","output_type":"stream"},{"name":"stdout","text":"72.69213128089905s for query: 흑백요리사 박준우\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Merge youtube_comments with movie_rating_dataset","metadata":{}},{"cell_type":"code","source":"comments = pd.read_csv(\"youtube_comments.csv\")","metadata":{"execution":{"iopub.status.busy":"2025-05-01T06:21:21.025973Z","iopub.execute_input":"2025-05-01T06:21:21.027216Z","iopub.status.idle":"2025-05-01T06:21:21.167065Z","shell.execute_reply.started":"2025-05-01T06:21:21.02708Z","shell.execute_reply":"2025-05-01T06:21:21.166164Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"comments.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T06:21:27.026785Z","iopub.execute_input":"2025-05-01T06:21:27.027194Z","iopub.status.idle":"2025-05-01T06:21:27.047443Z","shell.execute_reply.started":"2025-05-01T06:21:27.027156Z","shell.execute_reply":"2025-05-01T06:21:27.046081Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"      Video_ID                                            Comment\n0  vebF7wUQLMo  《흑백요리사: 요리 계급 전쟁》, 9월 17일 넷플릭스에서 시청하세요: https:...\n1  vebF7wUQLMo                                            빽햄요리사ㄷㄷ\n2  vebF7wUQLMo                                               0:07\n3  vebF7wUQLMo                             백수저중에 옴진리교 교주가 있노 ㄷㄷㄷㄷ\n4  vebF7wUQLMo                  심사위원 등장씬은 대한민국 역대 등장씬 고트중에 하나다 ㄹㅇ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Video_ID</th>\n      <th>Comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>vebF7wUQLMo</td>\n      <td>《흑백요리사: 요리 계급 전쟁》, 9월 17일 넷플릭스에서 시청하세요: https:...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>vebF7wUQLMo</td>\n      <td>빽햄요리사ㄷㄷ</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>vebF7wUQLMo</td>\n      <td>0:07</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>vebF7wUQLMo</td>\n      <td>백수저중에 옴진리교 교주가 있노 ㄷㄷㄷㄷ</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>vebF7wUQLMo</td>\n      <td>심사위원 등장씬은 대한민국 역대 등장씬 고트중에 하나다 ㄹㅇ</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"## SKIP","metadata":{}},{"cell_type":"code","source":"import urllib.request\n# download naver movie ratings dataset\nurllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:28:13.682572Z","iopub.execute_input":"2024-10-30T06:28:13.682985Z","iopub.status.idle":"2024-10-30T06:28:15.360465Z","shell.execute_reply.started":"2024-10-30T06:28:13.682949Z","shell.execute_reply":"2024-10-30T06:28:15.359218Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"movie_data = pd.read_table('ratings.txt')\nmovie_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:28:36.960981Z","iopub.execute_input":"2024-10-30T06:28:36.961445Z","iopub.status.idle":"2024-10-30T06:28:37.755561Z","shell.execute_reply.started":"2024-10-30T06:28:36.961403Z","shell.execute_reply":"2024-10-30T06:28:37.754322Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"comments.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:43:07.797368Z","iopub.execute_input":"2024-10-30T06:43:07.797803Z","iopub.status.idle":"2024-10-30T06:43:07.808645Z","shell.execute_reply.started":"2024-10-30T06:43:07.797764Z","shell.execute_reply":"2024-10-30T06:43:07.807503Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"movie data length: {len(movie_data)}\")\nprint(f\"comments data length: {len(comments)}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:43:02.244443Z","iopub.execute_input":"2024-10-30T06:43:02.244862Z","iopub.status.idle":"2024-10-30T06:43:02.250785Z","shell.execute_reply.started":"2024-10-30T06:43:02.244826Z","shell.execute_reply":"2024-10-30T06:43:02.249519Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Merge two dataset because number of Comments dataset is not big enough to train word vectors.\ndf1_text = movie_data[['document']].rename(columns={'document': 'text'})\ndf2_text = comments[['Comment']].rename(columns={'Comment': 'text'})\n\n# merge movie_data and yt_comments_data\nmerged_df = pd.concat([df1_text, df2_text], ignore_index=True)\nmerged_df","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:40:53.34329Z","iopub.execute_input":"2024-10-30T06:40:53.343765Z","iopub.status.idle":"2024-10-30T06:40:53.39077Z","shell.execute_reply.started":"2024-10-30T06:40:53.343725Z","shell.execute_reply":"2024-10-30T06:40:53.389651Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# NULL check\nprint(merged_df.isnull().values.any())","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:41:29.090737Z","iopub.execute_input":"2024-10-30T06:41:29.091547Z","iopub.status.idle":"2024-10-30T06:41:29.113326Z","shell.execute_reply.started":"2024-10-30T06:41:29.091503Z","shell.execute_reply":"2024-10-30T06:41:29.112255Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_df = merged_df.dropna(how = 'any') # drop rows with null values\nprint(merged_df.isnull().values.any()) ","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:41:59.530628Z","iopub.execute_input":"2024-10-30T06:41:59.531094Z","iopub.status.idle":"2024-10-30T06:41:59.583306Z","shell.execute_reply.started":"2024-10-30T06:41:59.531053Z","shell.execute_reply":"2024-10-30T06:41:59.582214Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(merged_df)) ","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:42:08.188811Z","iopub.execute_input":"2024-10-30T06:42:08.189231Z","iopub.status.idle":"2024-10-30T06:42:08.194667Z","shell.execute_reply.started":"2024-10-30T06:42:08.189192Z","shell.execute_reply":"2024-10-30T06:42:08.193487Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# remove all characters other than Hangeul\nmerged_df['text'] = merged_df['text'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:44:27.013444Z","iopub.execute_input":"2024-10-30T06:44:27.01388Z","iopub.status.idle":"2024-10-30T06:44:27.475893Z","shell.execute_reply.started":"2024-10-30T06:44:27.013843Z","shell.execute_reply":"2024-10-30T06:44:27.474817Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SKIP END","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install konlpy","metadata":{"execution":{"iopub.status.busy":"2025-05-01T06:27:24.909704Z","iopub.execute_input":"2025-05-01T06:27:24.910169Z","iopub.status.idle":"2025-05-01T06:27:37.390781Z","shell.execute_reply.started":"2025-05-01T06:27:24.910127Z","shell.execute_reply":"2025-05-01T06:27:37.389523Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting konlpy\n  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\nCollecting JPype1>=0.7.0 (from konlpy)\n  Downloading jpype1-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from konlpy) (5.3.0)\nRequirement already satisfied: numpy>=1.6 in /opt/conda/lib/python3.10/site-packages (from konlpy) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from JPype1>=0.7.0->konlpy) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->JPype1>=0.7.0->konlpy) (3.1.2)\nDownloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading jpype1-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (494 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: JPype1, konlpy\nSuccessfully installed JPype1-1.5.2 konlpy-0.6.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from konlpy.tag import Okt\nokt = Okt()","metadata":{"execution":{"iopub.status.busy":"2025-05-01T06:27:42.362914Z","iopub.execute_input":"2025-05-01T06:27:42.363864Z","iopub.status.idle":"2025-05-01T06:27:43.517369Z","shell.execute_reply.started":"2025-05-01T06:27:42.363814Z","shell.execute_reply":"2025-05-01T06:27:43.516248Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# NULL check\nprint(comments.isnull().values.any()) # => True\n\ncomments = comments.dropna(how = 'any') # drop rows with null values\n\nprint(comments.isnull().values.any()) # => False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T06:27:51.979542Z","iopub.execute_input":"2025-05-01T06:27:51.980291Z","iopub.status.idle":"2025-05-01T06:27:52.015059Z","shell.execute_reply.started":"2025-05-01T06:27:51.980246Z","shell.execute_reply":"2025-05-01T06:27:52.013859Z"}},"outputs":[{"name":"stdout","text":"True\nFalse\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n\ntokenized_data = []\n\n# merged_df['text'] => comments['Comment']\nfor sentence in tqdm.tqdm(comments['Comment']): \n    sentence = str(sentence).strip()\n    \n    if not sentence:  # 빈 문자열이면 건너뛰기\n        continue\n        \n    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n    stopwords_removed_sentence = [word for word in tokenized_sentence \n                                  if not word in stopwords # 조건1\n                                     and len(word) >= 2 # 조건2   \n                                     and word.isalpha()]  # 한글이나 영어 \n    \n    if stopwords_removed_sentence:  # 빈 리스트가 아니라면 추가\n        tokenized_data.append(stopwords_removed_sentence)\n","metadata":{"execution":{"iopub.status.busy":"2025-05-01T06:28:18.481225Z","iopub.execute_input":"2025-05-01T06:28:18.481637Z","iopub.status.idle":"2025-05-01T06:30:04.79823Z","shell.execute_reply.started":"2025-05-01T06:28:18.481599Z","shell.execute_reply":"2025-05-01T06:30:04.797134Z"},"trusted":true},"outputs":[{"name":"stderr","text":"100%|██████████| 41742/41742 [01:46<00:00, 392.66it/s]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"pip install gensim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T01:36:11.732002Z","iopub.execute_input":"2025-04-14T01:36:11.732647Z","iopub.status.idle":"2025-04-14T01:36:30.549604Z","shell.execute_reply.started":"2025-04-14T01:36:11.732609Z","shell.execute_reply":"2025-04-14T01:36:30.548186Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (4.3.3)\nRequirement already satisfied: numpy<2.0,>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.26.4)\nCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim) (7.0.4)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\nDownloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: scipy\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.14.1\n    Uninstalling scipy-1.14.1:\n      Successfully uninstalled scipy-1.14.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntsfresh 0.20.3 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scipy-1.13.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from gensim.models import Word2Vec\n\nmodel = Word2Vec(sentences = tokenized_data, vector_size = 100, window = 5, min_count = 5, workers = 4, sg = 0)","metadata":{"execution":{"iopub.status.busy":"2025-04-14T01:36:34.143349Z","iopub.execute_input":"2025-04-14T01:36:34.143758Z","iopub.status.idle":"2025-04-14T01:36:43.874842Z","shell.execute_reply.started":"2025-04-14T01:36:34.143719Z","shell.execute_reply":"2025-04-14T01:36:43.873814Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"model.wv.vectors.shape","metadata":{"execution":{"iopub.status.busy":"2025-04-14T01:36:48.378168Z","iopub.execute_input":"2025-04-14T01:36:48.378751Z","iopub.status.idle":"2025-04-14T01:36:48.38588Z","shell.execute_reply.started":"2025-04-14T01:36:48.378713Z","shell.execute_reply":"2025-04-14T01:36:48.384658Z"},"trusted":true},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(6492, 100)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"print(model.wv.most_similar(\"백종원\"))","metadata":{"execution":{"iopub.status.busy":"2025-01-22T03:13:22.199002Z","iopub.execute_input":"2025-01-22T03:13:22.199443Z","iopub.status.idle":"2025-01-22T03:13:22.210239Z","shell.execute_reply.started":"2025-01-22T03:13:22.199404Z","shell.execute_reply":"2025-01-22T03:13:22.208977Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[('성재', 0.9124249219894409), ('안성', 0.8956093192100525), ('기준', 0.8790994882583618), ('의원', 0.878623902797699), ('참가자', 0.8772395253181458), ('한테', 0.873734176158905), ('램지', 0.8582898378372192), ('고든', 0.8582121729850769), ('형평성', 0.8576611280441284), ('재는', 0.8506085872650146)]\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"print(model.wv.most_similar(\"최현석\"))","metadata":{"execution":{"iopub.status.busy":"2025-01-22T03:13:25.221265Z","iopub.execute_input":"2025-01-22T03:13:25.221689Z","iopub.status.idle":"2025-01-22T03:13:25.231754Z","shell.execute_reply.started":"2025-01-22T03:13:25.221652Z","shell.execute_reply":"2025-01-22T03:13:25.229237Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[('정지선', 0.9415532946586609), ('이랑', 0.9064624309539795), ('성재', 0.9025325179100037), ('여경', 0.9014614224433899), ('셰프', 0.8953206539154053), ('이영숙', 0.8883089423179626), ('안유', 0.8773502111434937), ('헤드', 0.8700518012046814), ('호준', 0.8651288747787476), ('제자', 0.8638734221458435)]\n","output_type":"stream"}],"execution_count":60},{"cell_type":"markdown","source":"## Save W2V model","metadata":{}},{"cell_type":"code","source":"model.wv.save_word2vec_format('ko_w2v')","metadata":{"execution":{"iopub.status.busy":"2025-04-14T01:37:05.648016Z","iopub.execute_input":"2025-04-14T01:37:05.648422Z","iopub.status.idle":"2025-04-14T01:37:06.115316Z","shell.execute_reply.started":"2025-04-14T01:37:05.648387Z","shell.execute_reply":"2025-04-14T01:37:06.114497Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"!python -m gensim.scripts.word2vec2tensor --input ko_w2v --output ko_w2v","metadata":{"execution":{"iopub.status.busy":"2025-04-14T01:37:09.951252Z","iopub.execute_input":"2025-04-14T01:37:09.952234Z","iopub.status.idle":"2025-04-14T01:37:17.346938Z","shell.execute_reply.started":"2025-04-14T01:37:09.952191Z","shell.execute_reply":"2025-04-14T01:37:17.345653Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## Visualization for embedding","metadata":{}},{"cell_type":"code","source":"## Go to https://projector.tensorflow.org/\n## and load ko_w2v_tensor.tsv and ko_w2v_metadata.tsv","metadata":{},"outputs":[],"execution_count":null}]}